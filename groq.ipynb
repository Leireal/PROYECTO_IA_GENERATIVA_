{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a28718",
   "metadata": {},
   "source": [
    "## Prueba de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c1cfa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq\n",
      "  Downloading groq-0.29.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from groq)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from groq)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from groq)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from groq)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "     ---------------------------------------- 0.0/68.0 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 61.4/68.0 kB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 68.0/68.0 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting sniffio (from groq)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\leire al\\appdata\\roaming\\python\\python311\\site-packages (from groq) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\leire al\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\leire al\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2025.4.26)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->groq)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->groq)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->groq)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading groq-0.29.0-py3-none-any.whl (130 kB)\n",
      "   ---------------------------------------- 0.0/130.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 130.8/130.8 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.9/100.9 kB ? eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.5/73.5 kB ? eta 0:00:00\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.8/78.8 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "   ---------------------------------------- 0.0/444.8 kB ? eta -:--:--\n",
      "   --------------------------------------  440.3/444.8 kB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 444.8/444.8 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.7/2.0 MB 22.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/2.0 MB 24.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 20.7 MB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-inspection, sniffio, pydantic-core, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, groq\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 distro-1.9.0 groq-0.29.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 pydantic-2.11.7 pydantic-core-2.33.2 sniffio-1.3.1 typing-inspection-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1fc17c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\leire al\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef06d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in various applications, including natural language processing (NLP), artificial intelligence (AI), and machine learning (ML). The importance of fast language models can be understood from the following perspectives:\n",
      "\n",
      "1. **Efficient Processing**: Fast language models enable rapid processing of large amounts of text data, which is essential for real-time applications such as language translation, sentiment analysis, and text classification. This efficiency allows for faster decision-making and improved overall system performance.\n",
      "2. **Scalability**: Fast language models can handle massive volumes of data, making them suitable for large-scale NLP tasks, such as text summarization, question answering, and information retrieval. This scalability is critical for applications that involve big data, such as social media monitoring, customer service chatbots, and content analysis.\n",
      "3. **Improved User Experience**: Fast language models can enhance user experience in various applications, such as:\n",
      "\t* Virtual assistants (e.g., Siri, Alexa, Google Assistant): Rapid response times enable seamless interactions and more accurate results.\n",
      "\t* Language translation apps: Fast language models facilitate real-time translation, enabling users to communicate more effectively across languages.\n",
      "\t* Chatbots and customer service platforms: Quick response times improve user satisfaction and reduce waiting times.\n",
      "4. **Competitive Advantage**: Organizations that adopt fast language models can gain a competitive edge in various industries, such as:\n",
      "\t* Customer service: Faster response times and more accurate results can lead to increased customer satisfaction and loyalty.\n",
      "\t* Marketing and advertising: Fast language models can help analyze large amounts of text data, enabling more informed marketing decisions and personalized advertising.\n",
      "\t* Healthcare: Rapid analysis of medical texts and patient data can improve diagnosis, treatment, and patient outcomes.\n",
      "5. **Reduced Latency**: Fast language models minimize latency, which is critical in applications where timely responses are essential, such as:\n",
      "\t* Emergency services (e.g., 911, ambulance): Quick language processing can help emergency responders provide faster and more effective assistance.\n",
      "\t* Financial transactions: Fast language models can help detect and prevent fraudulent activities in real-time.\n",
      "6. **Cost Savings**: Fast language models can reduce computational costs and energy consumption, making them more environmentally friendly and cost-effective. This is particularly important for large-scale NLP applications, where computational resources can be substantial.\n",
      "7. **Enhanced Accuracy**: Fast language models can lead to improved accuracy in various NLP tasks, such as:\n",
      "\t* Sentiment analysis: Rapid analysis of large amounts of text data can provide more accurate insights into customer opinions and preferences.\n",
      "\t* Text classification: Fast language models can classify text more accurately, enabling better information retrieval and filtering.\n",
      "8. **Real-time Insights**: Fast language models enable real-time insights and analytics, which are essential for applications that require up-to-the-minute information, such as:\n",
      "\t* Social media monitoring: Fast language models can analyze large amounts of social media data, providing real-time insights into public opinions and trends.\n",
      "\t* News and media analysis: Rapid analysis of news articles and media content can help identify breaking news and emerging trends.\n",
      "\n",
      "In summary, fast language models are crucial for efficient processing, scalability, improved user experience, competitive advantage, reduced latency, cost savings, enhanced accuracy, and real-time insights. As NLP and AI continue to evolve, the importance of fast language models will only continue to grow.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
